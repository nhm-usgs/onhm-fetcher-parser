{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Client</h3>\n",
       "<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n",
       "  <li><b>Scheduler: </b>tcp://127.0.0.1:56276</li>\n",
       "  <li><b>Dashboard: </b><a href='http://127.0.0.1:8787/status' target='_blank'>http://127.0.0.1:8787/status</a>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Cluster</h3>\n",
       "<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n",
       "  <li><b>Workers: </b>4</li>\n",
       "  <li><b>Cores: </b>8</li>\n",
       "  <li><b>Memory: </b>34.16 GB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: scheduler='tcp://127.0.0.1:56276' processes=4 cores=8>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%pylab inline\n",
    "pylab.rcParams['figure.figsize'] = (10.0, 8.0)\n",
    "\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import glob\n",
    "import zipfile\n",
    "import rasterio\n",
    "import os\n",
    "import xarray as xr\n",
    "import json\n",
    "from rasterstats import zonal_stats\n",
    "from rasterio.transform import from_origin\n",
    "\n",
    "import dask.multiprocessing\n",
    "dask.config.set(scheduler='processes')  # overwrite default with multiprocessing scheduler\n",
    "\n",
    "from dask.distributed import Client\n",
    "client = Client()\n",
    "# or\n",
    "# client = Client(processes=False)\n",
    "client\n",
    "# gpd.version.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B:\\GitRepos\\onhm-fetcher-parser\\notebooks\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Open Gridmet max temperature with geopandas and plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B:\\GitRepos\\onhm-fetcher-parser\\notebooks\n",
      "..\\Data\n",
      "       LAYER    POI_ID                                           geometry  \\\n",
      "0        NaN   7733855  POLYGON ((-73.37147648799998 41.11232830300003...   \n",
      "1        NaN   7733919  POLYGON ((-73.38531621599998 41.13467480400004...   \n",
      "2        NaN   7732571  POLYGON ((-73.41946539799994 41.16068341300007...   \n",
      "3        NaN   7732387  POLYGON ((-73.41096625099993 41.15832593000005...   \n",
      "4        NaN   7733327  (POLYGON ((-73.28636293699998 41.1278083500000...   \n",
      "...      ...       ...                                                ...   \n",
      "109946   NaN   4439814  POLYGON ((-123.682760808 41.59421288900006, -1...   \n",
      "109947   NaN   2551733  (POLYGON ((-121.3264525819999 42.3195167990000...   \n",
      "109948   NaN   2551733  POLYGON ((-121.149442958 42.23413625600006, -1...   \n",
      "109949   NaN  24081601  POLYGON ((-121.441435272 42.80623224900006, -1...   \n",
      "109950   NaN  24081601  (POLYGON ((-121.351904323 42.77765434300005, -...   \n",
      "\n",
      "        hru_id_nat  hru_id_reg region  \n",
      "0                1           1     01  \n",
      "1                2           2     01  \n",
      "2                3           3     01  \n",
      "3                4           4     01  \n",
      "4                5           5     01  \n",
      "...            ...         ...    ...  \n",
      "109946      109947        5833     18  \n",
      "109947      109948        5834     18  \n",
      "109948      109949        5835     18  \n",
      "109949      109950        5836     18  \n",
      "109950      109951        5837     18  \n",
      "\n",
      "[109951 rows x 6 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rmcd\\anaconda3\\envs\\ofp_env_dask\\lib\\site-packages\\ipykernel_launcher.py:9: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd())\n",
    "from pathlib import Path\n",
    "folder = Path(r'../Data') # assumes working directory is onhm-fetcher-parser\n",
    "print(folder)\n",
    "#shapefiles = folder.glob(\"*_0[1-2].shp\")\n",
    "shapefiles = folder.glob(\"*.shp\")\n",
    "gdf = pd.concat([\n",
    "    gpd.read_file(shp)\n",
    "    for shp in shapefiles\n",
    "]).pipe(gpd.GeoDataFrame)\n",
    "gdf.reset_index(drop=True, inplace=True)\n",
    "# gdf.plot()\n",
    "print(gdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Open Gridmet data (as netcdf file) print out some metadata\n",
    "This first bit of code follows examples from the following link:https://climate.northwestknowledge.net/MACA/OPENDAP.php\n",
    "First we open the data set and inspect the metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://thredds.northwestknowledge.net:8080/thredds/dodsC/MET/tmmx/tmmx_2019.nc\n",
      "<xarray.Dataset>\n",
      "Dimensions:          (crs: 1, day: 307, lat: 585, lon: 1386)\n",
      "Coordinates:\n",
      "  * lat              (lat) float64 49.4 49.36 49.32 49.28 ... 25.15 25.11 25.07\n",
      "  * day              (day) datetime64[ns] 2019-01-01 2019-01-02 ... 2019-11-03\n",
      "  * crs              (crs) float32 3.0\n",
      "  * lon              (lon) float64 -124.8 -124.7 -124.7 ... -67.14 -67.1 -67.06\n",
      "Data variables:\n",
      "    air_temperature  (day, lat, lon) float32 ...\n",
      "Attributes:\n",
      "    geospatial_bounds_crs:      EPSG:4326\n",
      "    Conventions:                CF-1.6\n",
      "    geospatial_bounds:          POLYGON((-124.7666666333333 49.40000000000000...\n",
      "    geospatial_lat_min:         25.066666666666666\n",
      "    geospatial_lat_max:         49.40000000000000\n",
      "    geospatial_lon_min:         -124.7666666333333\n",
      "    geospatial_lon_max:         -67.058333300000015\n",
      "    geospatial_lon_resolution:  0.041666666666666\n",
      "    geospatial_lat_resolution:  0.041666666666666\n",
      "    geospatial_lat_units:       decimal_degrees north\n",
      "    geospatial_lon_units:       decimal_degrees east\n",
      "    coordinate_system:          EPSG:4326\n",
      "    author:                     John Abatzoglou - University of Idaho, jabatz...\n",
      "    date:                       04 November 2019\n",
      "    note1:                      The projection information for this file is: ...\n",
      "    note2:                      Citation: Abatzoglou, J.T., 2013, Development...\n",
      "    last_permanent_slice:       247\n",
      "    last_early_slice:           307\n",
      "    last_provisional_slice:     301\n",
      "    note3:                      Data in slices after last_permanent_slice (1-...\n",
      "    note4:                      Data in slices after last_provisional_slice (...\n",
      "    note5:                      Days correspond approximately to calendar day...\n",
      "\n",
      " The meta data is: \n",
      " {\n",
      "    \"geospatial_bounds_crs\": \"EPSG:4326\",\n",
      "    \"Conventions\": \"CF-1.6\",\n",
      "    \"geospatial_bounds\": \"POLYGON((-124.7666666333333 49.400000000000000, -124.7666666333333 25.066666666666666, -67.058333300000015 25.066666666666666, -67.058333300000015 49.400000000000000, -124.7666666333333 49.400000000000000))\",\n",
      "    \"geospatial_lat_min\": \"25.066666666666666\",\n",
      "    \"geospatial_lat_max\": \"49.40000000000000\",\n",
      "    \"geospatial_lon_min\": \"-124.7666666333333\",\n",
      "    \"geospatial_lon_max\": \"-67.058333300000015\",\n",
      "    \"geospatial_lon_resolution\": \"0.041666666666666\",\n",
      "    \"geospatial_lat_resolution\": \"0.041666666666666\",\n",
      "    \"geospatial_lat_units\": \"decimal_degrees north\",\n",
      "    \"geospatial_lon_units\": \"decimal_degrees east\",\n",
      "    \"coordinate_system\": \"EPSG:4326\",\n",
      "    \"author\": \"John Abatzoglou - University of Idaho, jabatzoglou@uidaho.edu\",\n",
      "    \"date\": \"04 November 2019\",\n",
      "    \"note1\": \"The projection information for this file is: GCS WGS 1984.\",\n",
      "    \"note2\": \"Citation: Abatzoglou, J.T., 2013, Development of gridded surface meteorological data for ecological applications and modeling, International Journal of Climatology, DOI: 10.1002/joc.3413\",\n",
      "    \"last_permanent_slice\": \"247\",\n",
      "    \"last_early_slice\": \"307\",\n",
      "    \"last_provisional_slice\": \"301\",\n",
      "    \"note3\": \"Data in slices after last_permanent_slice (1-based) are considered provisional and subject to change with subsequent updates\",\n",
      "    \"note4\": \"Data in slices after last_provisional_slice (1-based) are considered early and subject to change with subsequent updates\",\n",
      "    \"note5\": \"Days correspond approximately to calendar days ending at midnight, Mountain Standard Time (7 UTC the next calendar day)\"\n",
      "}\n",
      "\n",
      " Data attributes, sizes, and coords \n",
      "\n",
      "\n",
      " Data sizes are: \n",
      " Frozen(OrderedDict([('day', 307), ('lat', 585), ('lon', 1386)]))\n",
      "\n",
      " Data coords are: \n",
      " Coordinates:\n",
      "  * lat      (lat) float64 49.4 49.36 49.32 49.28 ... 25.19 25.15 25.11 25.07\n",
      "  * day      (day) datetime64[ns] 2019-01-01 2019-01-02 ... 2019-11-03\n",
      "  * lon      (lon) float64 -124.8 -124.7 -124.7 -124.6 ... -67.14 -67.1 -67.06\n",
      "<class 'xarray.core.utils.Frozen'>\n",
      "307\n",
      "307 1386 585\n"
     ]
    }
   ],
   "source": [
    "#=========================================================\n",
    "#            MACAV2METDATA FILE PARAMETERS\n",
    "#=========================================================\n",
    "dirPath='http://thredds.northwestknowledge.net:8080'\n",
    "fileName='/thredds/dodsC/MET/tmmx/tmmx_2019.nc'\n",
    "\n",
    "#--------------------------------------------------------\n",
    "#   FORM FILENAME AND GET HANDLE TO FILE AND DATA\n",
    "#--------------------------------------------------------\n",
    "fullfilename= dirPath+fileName\n",
    "print(fullfilename)\n",
    "\n",
    "ds = xr.open_dataset(fullfilename)\n",
    "\n",
    "print(ds)\n",
    "\n",
    "# df = ds.to_dataframe()\n",
    "\n",
    "print('\\n The meta data is: \\n', json.dumps(ds.attrs, indent=4))\n",
    "lathandle=ds['lat']\n",
    "lonhandle=ds['lon']\n",
    "timehandle=ds['day']\n",
    "datahandle=ds['air_temperature']\n",
    "crshandle=ds['crs']\n",
    "# print('\\n The crs meta data is \\n', json.dumps(crshandle.attrs, indent=4))\n",
    "\n",
    "# crstransform = crshandle.attrs['GeoTransform']\n",
    "# print(crstransform)\n",
    "\n",
    "#collect data to describe geotransform\n",
    "lonmin = float(ds.attrs['geospatial_lon_min'])\n",
    "latmax = float(ds.attrs['geospatial_lat_max'])\n",
    "lonres = float(ds.attrs['geospatial_lon_resolution'])\n",
    "latres = float(ds.attrs['geospatial_lon_resolution'])\n",
    "\n",
    "#Print some information on the data\n",
    "\n",
    "print('\\n Data attributes, sizes, and coords \\n') \n",
    "# print('\\n Data attributes are: \\n', json.dumps(datahandle.attrs, indent=4))\n",
    "print('\\n Data sizes are: \\n', datahandle.sizes)\n",
    "print('\\n Data coords are: \\n', datahandle.coords)\n",
    "\n",
    "ts = datahandle.sizes\n",
    "print(type(ts))\n",
    "print(ts['day'])\n",
    "dayshape = ts['day']\n",
    "Lonshape = ts['lon']\n",
    "Latshape = ts['lat']\n",
    "#dayshape,lonshape,latshape = datahandle.values.shape\n",
    "print(dayshape, Lonshape, Latshape)\n",
    "\n",
    "# datahandle.values[dayshape-1,:,:].shape\n",
    "\n",
    "# print(lathandle.values.shape)\n",
    "# print(type(lathandle.values))\n",
    "# print(datahandle.dtype)\n",
    "# print(np.isfortran(datahandle.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.DataArray 'air_temperature' ()>\n",
      "array(nan, dtype=float32)\n",
      "Coordinates:\n",
      "    lat      float64 29.4\n",
      "    day      datetime64[ns] 2019-11-03\n",
      "    lon      float64 -73.43\n",
      "Attributes:\n",
      "    units:              K\n",
      "    description:        Daily Maximum Temperature\n",
      "    long_name:          tmmx\n",
      "    standard_name:      tmmx\n",
      "    dimensions:         lon lat time\n",
      "    grid_mapping:       crs\n",
      "    coordinate_system:  WGS84,EPSG:4326\n",
      "    _ChunkSizes:        [ 52 117 278]\n"
     ]
    }
   ],
   "source": [
    "print(datahandle[dayshape-1, 480, 1232])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add netcdf data (tmax here) to dataframe that has hru id and geometry\n",
    "* use weight file to assign tmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testnan(value, weight):\n",
    "    if np.isnan(value): \n",
    "        tvalue = 0.0\n",
    "        tweight = 0.0\n",
    "    else:\n",
    "        tvalue = value\n",
    "        tweight = weight\n",
    "    return tvalue, tweight\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(data))\n",
    "# print(data.shape)\n",
    "# print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test with Pandas groupby alternative to original method in following cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   grid_ids  hru_id_nat         w\n",
      "0    278433           1  0.000120\n",
      "1    277046           1  0.031155\n",
      "2    277047           1  0.901587\n",
      "3    277048           1  0.046570\n",
      "4    275661           1  0.020568\n",
      "[nan nan nan ... nan nan nan]\n",
      "109951 109951\n",
      "<class 'numpy.float64'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rmcd\\anaconda3\\envs\\ofp_env_dask\\lib\\site-packages\\ipykernel_launcher.py:45: UserWarning: Warning: converting a masked element to nan.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min/max -8.392208682988269 30.370646235051368\n"
     ]
    }
   ],
   "source": [
    "# add tmax column to dataframe\n",
    "gdf['tmax']=0.0\n",
    "\n",
    "#open weight data\n",
    "# wght_df = pd.read_csv('../Data/hru_metdata_weights.csv')\n",
    "# wght_df_40 = pd.read_csv('../Data/hru_metdata_weights_40m.csv')\n",
    "# wght_df_500 = pd.read_csv('../Data/hru_metdata_weights_500m.csv')\n",
    "# wght_UofI = pd.read_csv('../Data/hru_uofimetdata_weights.csv')\n",
    "wght_UofI = pd.read_csv('weights.csv')\n",
    "# print(len(wght_df['hru_id_nat'].unique()), len(wght_df_40['hru_id_nat'].unique()), \n",
    "#       len(wght_df_500['hru_id_nat'].unique()), len(wght_UofI['hru_id_nat'].unique()))\n",
    "print(wght_UofI.head())\n",
    "\n",
    "#iterate through hru's, grab all weights associated with hru_id, get total weighted value from netcdf file, assign to tmax\n",
    "ndata = datahandle.values[dayshape-1,:,:].flatten(order='K')\n",
    "# ndata=np.nan_to_num(data)\n",
    "print(ndata[1000:])\n",
    "# def w_mean(data)\n",
    "unique_hru_ids = wght_UofI.groupby('hru_id_nat')\n",
    "print(len(gdf), len(unique_hru_ids))\n",
    "\n",
    "def get_wval(grp, ndata):\n",
    "    ttmax = twght = 0.0\n",
    "    for index, row in grp.iterrows():\n",
    "        ttmax += row['w']*ndata[np.int(row['grid_ids'])]\n",
    "        twght += row['w']\n",
    "    return ttmax/twght\n",
    "def np_get_wval(grp, ndata):\n",
    "    return np.average(ndata[grp['grid_ids'].values.astype(int)], weights=grp['w'])\n",
    "def np_get_wval2(grp, ndata):\n",
    "    mdata = np.ma.masked_array(ndata[grp['grid_ids'].values.astype(int)], np.isnan(ndata[grp['grid_ids'].values.astype(int)]))\n",
    "    return np.ma.average(mdata, weights=grp['w'])\n",
    "#     return np.average(ndata[grp['grid_ids'].values.astype(int)], weights=grp['w'])\n",
    "    \n",
    "# unique_hru_ids.get_group(gdf['hru_id_nat']).agg({'tmax': np_get_wval(weight_id_rows, ndata)})    \n",
    "td = np.zeros(len(gdf.index))\n",
    "for index, row in gdf.iterrows():\n",
    "    weight_id_rows = unique_hru_ids.get_group(row['hru_id_nat'])\n",
    "#     print(weight_id_rows['grid_ids'].values.astype(int))\n",
    "#     unique_hru_ids.get_group(row['hru_id_nat']).agg({'tmax': np_get_wval(weight_id_rows, ndata)})\n",
    "#     gdf.loc[gdf.index[index],'tmax'] = np_get_wval(weight_id_rows, ndata)-273.5\n",
    "    tmp = np_get_wval2(weight_id_rows, ndata)-273.5\n",
    "    if index == 1:\n",
    "        print(type(tmp))\n",
    "    td[index] = np_get_wval2(weight_id_rows, ndata)-273.5\n",
    "#     if td[index] < 0.0:\n",
    "#         print(ndata[weight_id_rows['grid_ids'].values.astype(int)], weight_id_rows['w'])\n",
    "#     print(index, td[index])\n",
    "#     if row['hru_id_nat'] == 829:\n",
    "#         print(\"in test\")\n",
    "#         for i2, el in weight_id_rows.iterrows():\n",
    "#             print(el['w'], ndata[el['grid_ids'].astype(int)])\n",
    "#         print(np.average(ndata[weight_id_rows['grid_ids'].values.astype(int)], weights=weight_id_rows['w'])-273.5)\n",
    "#     print(index, row['hru_id_nat'], np_get_wval(weight_id_rows, ndata)-273.5)\n",
    "#     gdf.loc[gdf.index[index], 'tmax'] =\n",
    "# #     print(get_wval(weight_id_rows, ndata)-273.5)\n",
    "# #     row.loc['tmax']=get_wval(weight_id_rows, ndata)-273.5\n",
    "# #     gdf.loc[gdf.index[index], 'tmax'] = get_wval(weight_id_rows, ndata)-273.5\n",
    "# print(len(td))\n",
    "# gdf['tmax'] = gpd.GeoSeries([np.transpose(td)], index=gdf.index)\n",
    "gdf['tmax'] = td.tolist()\n",
    "gdf['tmax'].fillna(0.0)\n",
    "# print(td.tolist())\n",
    "print('min/max', gdf['tmax'].min(), gdf['tmax'].max())\n",
    "# print(gdf)\n",
    "# gdf.plot(figsize=(12,12), column = 'tmax',linewidth=0.25, edgecolor='white')    \n",
    "# print(gdf.groupby(tmax).min)\n",
    "# f, ax = plt.subplots(2, figsize=(12,12))\n",
    "# gdf.plot(ax=ax[0], column = 'tmax',linewidth=0., edgecolor='white', scheme='quantiles')\n",
    "# ptmax = ds.air_temperature-273.5\n",
    "# ptmax_1 = ptmax.isel(day=dayshape-1)\n",
    "# lvs = np.arange(gdf['tmax'].min(), gdf['tmax'].max(), 0.5)\n",
    "# ptmax_1.plot(ax=ax[1], levels=lvs, cmap='viridis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(unique_hru_ids.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "f, ax = plt.subplots(1)\n",
    "ax.set_aspect('equal')\n",
    "# ax.axis('equal')\n",
    "# ax1.set(xlim=(-130, -60), ylim=(20, 55))\n",
    "# divider_0 = make_axes_locatable(ax[0])\n",
    "# cax_0 = divider_0.append_axes(\"right\", size=\"5%\", pad=0.1)\n",
    "lvs = np.arange(gdf['tmax'].min(), gdf['tmax'].max(), 0.1)\n",
    "gdf.plot(ax=ax, column = 'tmax',linewidth=0., edgecolor='white', cmap='viridis', k=20)\n",
    "f.savefig('hru.png')\n",
    "f.tight_layout()\n",
    "f1, ax1 = plt.subplots(1)\n",
    "ax1.set_aspect('equal')\n",
    "# ax1.set(xlim=(-130, -60), ylim=(20, 55))\n",
    "ptmax = ds.air_temperature-273.5\n",
    "ptmax_1 = ptmax.isel(day=dayshape-1)\n",
    "ptmax_1.plot(ax=ax1, levels=lvs, cmap='viridis')\n",
    "f1.tight_layout()\n",
    "f1.savefig('gridmet.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(ptmax_1))\n",
    "print(type(gdf))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add tmax column to dataframe\n",
    "gdf['tmax']=None\n",
    "\n",
    "#open weight data\n",
    "wght_df = pd.read_csv('../Data/hru_metdata_weights.csv')\n",
    "wght_df_40 = pd.read_csv('../Data/hru_metdata_weights_40m.csv')\n",
    "wght_df_500 = pd.read_csv('../Data/hru_metdata_weights_500m.csv')\n",
    "wght_UofI = pd.read_csv('../Data/hru_uofimetdata_weights.csv')\n",
    "print(len(wght_df['hru_id_nat'].unique()), len(wght_df_40['hru_id_nat'].unique()), len(wght_df_500['hru_id_nat'].unique()))\n",
    "print(wght_df.head())\n",
    "\n",
    "#iterate through hru's, grab all weights associated with hru_id, get total weighted value from netcdf file, assign to tmax\n",
    "unique_hru_ids = wght_UofI['hru_id_nat'].unique()\n",
    "print(len(gdf), len(unique_hru_ids))\n",
    "ndata=datahandle.values[dayshape-1,:,:].flatten(order='C')\n",
    "for index, row in gdf.iterrows():\n",
    "    weight_id_rows = wght_UofI.loc[wght_UofI['hru_id_nat'] == row['hru_id_nat']]\n",
    "    ttmax = 0.0\n",
    "    twght = 0.0\n",
    "    tcount = 0\n",
    "    # based on above metadata the shape of the netcdf file is day,lat(y),lon(x)\n",
    "    for ind2, rw2 in weight_id_rows.iterrows():\n",
    "#           print(rw2['Y_ind'],rw2['X_ind'])\n",
    "#         tval, twt = testnan(datahandle.values[dayshape-1,int(rw2['Y_ind']),int(rw2['X_ind'])], rw2['w'])\n",
    "        tval, twt = testnan(ndata[rw2['grid_ids'].astype(int)], rw2['w'])\n",
    "        if twt > 0.0:\n",
    "            ttmax += twt*tval\n",
    "            twght += twt\n",
    "            tcount += 1\n",
    "#           if index == 4512: # test that discovered some weights associated with intesecting cells that are outside conus and return nan values\n",
    "#               print(ind2, rw2['w'], ttmax, twght, tcount, datahandle.values[dayshape-1,int(rw2['Y_ind']),int(rw2['X_ind'])], rw2['Y_ind'], rw2['X_ind'])\n",
    "    print(index, row['hru_id_nat'], tcount, ttmax, twght, ((ttmax/twght)-273.15))\n",
    "    gdf.loc[gdf.index[index], 'tmax'] = ((ttmax/twght)-273.15)\n",
    "#         data.setvalue(index, 'tmax', ((ttmax/twght)-273.15) * 9/5 + 32)\n",
    "#         print('tmp', hru_id, row['tmax'])\n",
    "# print(gdf)\n",
    "# gdf.plot()\n",
    "# f, ax = plt.subplots(2, figsize=(8,6))\n",
    "# gdf.plot(ax=ax[0], column = 'tmax')\n",
    "# ptmax = ds.air_temperature-273.5\n",
    "# ptmax_1 = ptmax.isel(day=dayshape-1)\n",
    "# ptmax_1.plot(ax=ax[1], levels=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert netcdf to geotiff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat = lathandle.values\n",
    "lon = lonhandle.values\n",
    "\n",
    "transform = from_origin( lonmin, latmax, lonres, latres)\n",
    "# res = (lon[-1] - lon[0])/lon.shape[0]\n",
    "# print(res)\n",
    "# transform2 = from_origin(lon[0]-res/2, lat[-1]+res/2, res, res) \n",
    "# print(transform, transform2)\n",
    "new_dataset = rasterio.open(r'C:\\Users\\rmcd\\Documents\\oNHM\\GeospatialFabric_1\\nhru\\unzip\\test1.tif', 'w', driver='GTiff',\n",
    "                            height = lonshape, width = latshape,\n",
    "                            count=1, dtype=str(datahandle.dtype),\n",
    "                            crs={'init': 'epsg:4326'},\n",
    "                            transform=transform)\n",
    "# vals = np.transpose(datahandle.values, [1,2,0])\n",
    "# vals2 = vals[:,:,85-1]\n",
    "vals = datahandle.values[dayshape-1, :, :]\n",
    "print(vals.shape)\n",
    "# im = np.transpose(vals, [1,2,0])\n",
    "# fa = np.asfortranarray(vals)\n",
    "# ca = np.asanyarray(vals, order='C')\n",
    "ud = (np.flipud(vals)-273.15) * 9/5 + 32\n",
    "# at = np.transpose(vals)\n",
    "# atf = np.rot90(at)\n",
    "new_dataset.write(ud, 1)\n",
    "# new_dataset.warp.transform\n",
    "# print(new_dataset.transform)\n",
    "# pyplot.imshow(new_dataset.read(1), cmap='pink')\n",
    "# pyplot.show()\n",
    "print(new_dataset)\n",
    "new_dataset.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot geotiff raster data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(r'C:\\Users\\rmcd\\Documents\\oNHM\\GeospatialFabric_1\\nhru\\unzip')\n",
    "with rasterio.open(r'test1.tif') as src:\n",
    "    transform = src.meta['transform']\n",
    "    print(type(transform), src.meta)\n",
    "    array = src.read(1)\n",
    "print(src)\n",
    "plt.imshow(array, interpolation='nearest')\n",
    "plt.colorbar()\n",
    "plt.title('max temp')\n",
    "plt.show()\n",
    "src.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform zonal stats using rasterstats with the geotiff raster and hru shapefile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geoplot as gplt\n",
    "\n",
    "print(transform)\n",
    "with rasterio.open(r'test1.tif') as src:\n",
    "    transform = src.meta['transform']\n",
    "    print(type(transform), src.meta)\n",
    "    array = src.read(1)\n",
    "\n",
    "hrudata = gpd.GeoDataFrame.from_file(r'nhru_02.shp')\n",
    "\n",
    "stats = zonal_stats(hrudata, array, transform=transform.to_gdal(), prefix='tmax_', all_touched=True)\n",
    "statsdf = pd.DataFrame(stats)\n",
    "src.close()\n",
    "\n",
    "print(statsdf.head())\n",
    "\n",
    "zonalhru = hrudata.join(statsdf)\n",
    "\n",
    "# # print(stats)\n",
    "# # newhru = hrudata.join(gpd.DataFrame(stats))\n",
    "# # print(newhru.head())\n",
    "zonalhru.__class__ = gpd.GeoDataFrame\n",
    "zonalhru.crs={}\n",
    "zonalhru.set_geometry('geometry')\n",
    "# ax = gplt.pointplot(zonalhru['mean'])\n",
    "# gplt.polyplot()\n",
    "# geoplot.choropleth(zonalhru, hue='mean', cmap='viridis', k = 20, \n",
    "#                 linewidth=0.5, legend=True)\n",
    "zonalhru.plot(column='tmax_mean', cmap='viridis')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alternative Rasterstats method: \n",
    "* https://geohackweek.github.io/vector/06-geopandas-advanced/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio\n",
    "import rasterio.plot as rioplot\n",
    "import cartopy.crs as ccrs\n",
    "\n",
    "# print(transform)\n",
    "with rasterio.open(r'test1.tif') as src:\n",
    "    transformb = src.meta['transform']\n",
    "    print(type(transformb), src.meta)\n",
    "    array = src.read(1)\n",
    "rasterdata = rasterio.open(r'test1.tif')\n",
    "tmp = rioplot.show(rasterdata, with_bounds=True, cmap='viridis', extent=([-82, -70, 36, 46]))\n",
    "print(tmp.axis)\n",
    "tmp.set_xlim([-82, -70])\n",
    "tmp.set_ylim([36, 46])\n",
    "hrudata = gpd.GeoDataFrame.from_file(r'nhru_02.shp')\n",
    "\n",
    "stats = zonal_stats(hrudata, r'test1.tif', transform=transformb.to_gdal(), prefix='tmax_', \n",
    "                    all_touched=True, geojson_out=True)\n",
    "# statsdf = pd.DataFrame(stats)\n",
    "# src.close()\n",
    "stats_gdf = gpd.GeoDataFrame.from_features(stats)\n",
    "print(stats_gdf.head())\n",
    "extent=([-82, -70, 36, 46])\n",
    "f, ax = plt.subplots(1, figsize=(8,6))\n",
    "ax.set_title(\"max temp\")\n",
    "stats_gdf.plot(ax=ax, column='tmax_mean', scheme='Equal_Interval', k=10, \n",
    "                   cmap='viridis', linewidth=0.25, edgecolor='black', \n",
    "                   legend=True, legend_kwds={'loc': 'upper left'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(stats_gdf.index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# write netcdf file using netcdf4\n",
    "* https://github.com/Unidata/netcdf4-python/blob/master/examples/writing_netCDF.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import netCDF4\n",
    "try: ncfile.close() # just to be safe, make sure dataset is not already open.\n",
    "except: pass\n",
    "ncfile = netCDF4.Dataset('new.nc',mode='w',format='NETCDF4_CLASSIC')\n",
    "\n",
    "# Global Attributes\n",
    "ncfile.Conventions = 'CF-1.8'\n",
    "ncfile.featureType = 'timeSeries'\n",
    "ncfile.history = ''\n",
    "\n",
    "sp_dim = len(stats_gdf.index)\n",
    "hruid_dim = ncfile.createDimension('hruid', sp_dim)     # hru_id\n",
    "time_dim = ncfile.createDimension('time', None) # unlimited axis (can be appended to).\n",
    "for dim in ncfile.dimensions.items():\n",
    "    print(dim)\n",
    "\n",
    "#Create Variables\n",
    "time = ncfile.createVariable('time', np.int, ('time', ))\n",
    "time.long_name = 'time'\n",
    "time.standard_name = 'time'\n",
    "time.units = 'days since '+'base_date'+' 00:00'+'time_zone'\n",
    "\n",
    "hru = ncfile.createVariable('hruid', np.int, ('hruid', ))\n",
    "hru.cf_role = 'timeseries_id'\n",
    "hru.long_name = 'local model hru id'\n",
    "\n",
    "lat = ncfile.createVariable('hru_lat', np.float32, ('hruid',))\n",
    "lat.long_name = 'Latitude of HRU centroid'\n",
    "lat.units = 'degrees_north'\n",
    "lat.standard_name = 'hru_latitude'\n",
    "\n",
    "lon = ncfile.createVariable('hru_lon', np.float32, ('hruid',))\n",
    "lon.long_name = 'Longitude of HRU centroid'\n",
    "lon.units = 'degrees_east'\n",
    "lon.standard_name = 'hru_longitude'\n",
    "\n",
    "prcp = ncfile.createVariable('prcp', np.float32, ('time', 'hruid'))\n",
    "prcp.long_name = 'Daily precipitation rate'\n",
    "prcp.units = 'mm/day'\n",
    "prcp.standard_name = 'lwe_precipitation_rate'\n",
    "\n",
    "tmax = ncfile.createVariable('tmax', np.float32, ('time', 'hruid'))\n",
    "tmax.long_name = 'Maximum daily air temperature'\n",
    "tmax.units = 'degree_Celsius'\n",
    "tmax.standard_name = 'maximum_daily_air_temperature'\n",
    "\n",
    "tmin = ncfile.createVariable('tmin', np.float32, ('time', 'hruid'))\n",
    "tmin.long_name = 'Minimum daily air temperature'\n",
    "tmin.units = 'degree_Celsius'\n",
    "tmin.standard_name = 'minimum_daily_air_temperature'\n",
    "\n",
    "# fill variables with available data\n",
    "def getXY(pt):\n",
    "    return (pt.x, pt.y)\n",
    "centroidseries = stats_gdf['geometry'].centroid\n",
    "tlon, tlat = [list(t) for t  in zip(*map(getXY, centroidseries))]\n",
    "# print(lon, lat)\n",
    "lon[:] = tlon\n",
    "lat[:] = tlat\n",
    "hru[:] = stats_gdf['hru_id_nat'].values\n",
    "# print(hruid)\n",
    "tmax[0,:] = stats_gdf['tmax_mean'].values\n",
    "\n",
    "print(ncfile)\n",
    "ncfile.close(); print(\"dataset is closed\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
