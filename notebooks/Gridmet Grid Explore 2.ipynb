{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%pylab inline\n",
    "pylab.rcParams['figure.figsize'] = (10.0, 8.0)\n",
    "\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import glob\n",
    "import zipfile\n",
    "import rasterio\n",
    "import os\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "from numpy.ma import masked\n",
    "import dask.dataframe as dd\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# gpd.version.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_gridmet(df, wght_id, wghts, data):\n",
    "    for index, row in df.iterrows():\n",
    "        try:\n",
    "            weight_id_rows = wghts.get_group(row[wght_id])\n",
    "            df.tmax.at[index] = np.nan_to_num(np_get_wval(data, weight_id_rows, row[wghts_id]) - 273.5)\n",
    "        except:\n",
    "            df.tmax.at[index] = netCDF4.default_fillvals['f8']\n",
    "            \n",
    "def map_gridmet_dask(df, wght_id, wghts, data):\n",
    "    for index, row in df.iterrows():\n",
    "        try:\n",
    "            weight_id_rows = wghts.get_group(row[wght_id])\n",
    "            tmp = np.nan_to_num(np_get_wval(data, weight_id_rows, row[wghts_id]) - 273.5)\n",
    "#             row.replace({'tmax':tmp})\n",
    "        except:\n",
    "            tmp = netCDF4.default_fillvals['f8']\n",
    "#             row.replace({'tmax':tmp})\n",
    "        df.loc[[index],['tmax']] = tmp\n",
    "            \n",
    "import netCDF4\n",
    "def np_get_wval(ndata, wghts, hru_id):\n",
    "    \"\"\"\n",
    "    Returns weighted average of ndata with weights = grp\n",
    "    1) mdata = the subset of values associated with the gridmet id's that are mapped to hru_id.\n",
    "    2) Some of these values may have nans if the gridmet id is outside of conus so only return values\n",
    "    that are inside of conus\n",
    "    3) this means that hru's that are entirely outside of conus will return nans which will ultimately,\n",
    "    outside of this function get assigned zero's.\n",
    "    4) the value is assigned the weighted average\n",
    "    :param ndata: float array of data values\n",
    "    :param wghts: float array of weights\n",
    "    :param hru_id hru id number\n",
    "    :return: numpy weighted averaged - masked to deal with nans associated with\n",
    "            ndata that is outside of the conus.\n",
    "    \"\"\"\n",
    "    mdata = np.ma.masked_array(ndata[wghts['grid_ids'].values.astype(int)],\n",
    "                               np.isnan(ndata[wghts['grid_ids'].values.astype(int)]))\n",
    "#     if np.ma.is_masked(mdata):\n",
    "#         print('returning masked value', hru_id)\n",
    "\n",
    "    # mdata = np.ma.masked_where(ndata[wghts['grid_ids'].values.astype(int)] <= 0.0,\n",
    "    #                            (ndata[wghts['grid_ids'].values.astype(int)]))\n",
    "    tmp = np.ma.average(mdata, weights=wghts['w'])\n",
    "    if tmp is masked:\n",
    "#         print('returning masked value', hru_id)\n",
    "        return netCDF4.default_fillvals['f8'] #np.nan\n",
    "\n",
    "    else:\n",
    "        return tmp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B:\\GitRepos\\onhm-fetcher-parser\\notebooks\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Open Gridmet max temperature with geopandas and plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B:\\GitRepos\\onhm-fetcher-parser\\notebooks\n",
      "..\\Data_v1_1\n",
      "               LAYER            GM_TYPE  OBJECTID  nhru_v11  hru_segme1  \\\n",
      "0       NHM\\nhru_v11  Unknown Area Type         1     76127       40038   \n",
      "1       NHM\\nhru_v11  Unknown Area Type         2     76147       40038   \n",
      "2       NHM\\nhru_v11  Unknown Area Type         3     76170       40021   \n",
      "3       NHM\\nhru_v11  Unknown Area Type         3     76170       40021   \n",
      "4       NHM\\nhru_v11  Unknown Area Type         3     76170       40021   \n",
      "...              ...                ...       ...       ...         ...   \n",
      "139802  NHM\\nhru_v11  Unknown Area Type    114954     57964       31028   \n",
      "139803  NHM\\nhru_v11  Unknown Area Type    114955     64080       28886   \n",
      "139804  NHM\\nhru_v11  Unknown Area Type    114956     64150       28866   \n",
      "139805  NHM\\nhru_v11  Unknown Area Type    114957     65633       31412   \n",
      "139806  NHM\\nhru_v11  Unknown Area Type    114958     18843       10081   \n",
      "\n",
      "        Shape_Leng Shape_Area  nhm_id  hru_id_nat  Version  \\\n",
      "0        92601.509  188151328   76128       76128      1.0   \n",
      "1        60460.683   44161889   76148       76148      1.0   \n",
      "2        62333.253   73375754   76171       76171      1.0   \n",
      "3        62333.253   73375754   76171       76171      1.0   \n",
      "4        62333.253   73375754   76171       76171      1.0   \n",
      "...            ...        ...     ...         ...      ...   \n",
      "139802  144351.030  255074262   57965       57965      1.0   \n",
      "139803   79361.920  110270903   64081       64081      1.0   \n",
      "139804   95810.807  188440874   64151       64151      1.0   \n",
      "139805   83210.536   73870743   65634       65634      1.0   \n",
      "139806  198719.270  222347333   18844       18844      1.0   \n",
      "\n",
      "                                                 geometry  \n",
      "0       POLYGON ((-97.09917176517163 30.3070901878905,...  \n",
      "1       POLYGON ((-97.01237487841129 30.3284568788036,...  \n",
      "2       POLYGON ((-97.11149162601821 30.41259208640142...  \n",
      "3       POLYGON ((-97.06283569337707 30.46034049964206...  \n",
      "4       POLYGON ((-97.06283569337707 30.46034049964206...  \n",
      "...                                                   ...  \n",
      "139802  POLYGON ((-100.0387954706423 47.50374984866188...  \n",
      "139803  POLYGON ((-112.6144360823938 45.90174042628251...  \n",
      "139804  POLYGON ((-113.4020309444318 45.74098968477336...  \n",
      "139805  POLYGON ((-109.6027056036111 48.16593182724034...  \n",
      "139806  POLYGON ((-90.16716003392685 48.13775253252872...  \n",
      "\n",
      "[139807 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd())\n",
    "from pathlib import Path\n",
    "# folder = Path(r'../Data') # assumes working directory is onhm-fetcher-parser\n",
    "folder = Path(r'../Data_v1_1') # assumes working directory is onhm-fetcher-parser\n",
    "print(folder)\n",
    "# shapefiles = folder.glob(\"*_0[1-2].shp\")\n",
    "shapefiles = folder.glob(\"*2e*.shp\")\n",
    "gdf = pd.concat([\n",
    "    gpd.read_file(shp)\n",
    "    for shp in shapefiles\n",
    "]).pipe(gpd.GeoDataFrame)\n",
    "gdf.reset_index(drop=True, inplace=True)\n",
    "# gdf.plot()\n",
    "print(gdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy onhm hru ID (here nhru_v11 into a new simple dataframe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Open Gridmet data (as netcdf file) print out some metadata\n",
    "This first bit of code follows examples from the following link:https://climate.northwestknowledge.net/MACA/OPENDAP.php\n",
    "First we open the data set and inspect the metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "removed existing file\n",
      "Success!\n",
      "http://thredds.northwestknowledge.net:8080/thredds/ncss/agg_met_tmmx_1979_CurrentYear_CONUS.nc?var=daily_maximum_temperature&disableLLSubset=on&disableProjSubset=on&horizStride=1&time_start=2018-12-31T00%3A00%3A00Z&time_end=2018-12-31T00%3A00%3A00Z&timeStride=1&accept=netcdf\n",
      "\n",
      " The meta data is: \n",
      " {\n",
      "    \"geospatial_bounds_crs\": \"EPSG:4326\",\n",
      "    \"Conventions\": \"CF-1.0\",\n",
      "    \"geospatial_bounds\": \"POLYGON((-124.7666666333333 49.400000000000000, -124.7666666333333 25.066666666666666, -67.058333300000015 25.066666666666666, -67.058333300000015 49.400000000000000, -124.7666666333333 49.400000000000000))\",\n",
      "    \"geospatial_lat_min\": 25.066666666666666,\n",
      "    \"geospatial_lat_max\": 49.400000000000006,\n",
      "    \"geospatial_lon_min\": -124.76666663333334,\n",
      "    \"geospatial_lon_max\": -67.05833330000002,\n",
      "    \"geospatial_lon_resolution\": \"0.041666666666666\",\n",
      "    \"geospatial_lat_resolution\": \"0.041666666666666\",\n",
      "    \"geospatial_lat_units\": \"decimal_degrees north\",\n",
      "    \"geospatial_lon_units\": \"decimal_degrees east\",\n",
      "    \"coordinate_system\": \"EPSG:4326\",\n",
      "    \"author\": \"John Abatzoglou - University of Idaho, jabatzoglou@uidaho.edu\",\n",
      "    \"date\": \"02 March 2020\",\n",
      "    \"note1\": \"The projection information for this file is: GCS WGS 1984.\",\n",
      "    \"note2\": \"Citation: Abatzoglou, J.T., 2013, Development of gridded surface meteorological data for ecological applications and modeling, International Journal of Climatology, DOI: 10.1002/joc.3413\",\n",
      "    \"note3\": \"Data in slices after last_permanent_slice (1-based) are considered provisional and subject to change with subsequent updates\",\n",
      "    \"note4\": \"Data in slices after last_provisional_slice (1-based) are considered early and subject to change with subsequent updates\",\n",
      "    \"note5\": \"Days correspond approximately to calendar days ending at midnight, Mountain Standard Time (7 UTC the next calendar day)\",\n",
      "    \"History\": \"Translated to CF-1.0 Conventions by Netcdf-Java CDM (CFGridWriter2)\\nOriginal Dataset = agg_met_tmmx_1979_CurrentYear_CONUS.nc; Translation Date = 2020-03-20T18:34:16.043Z\"\n",
      "}\n",
      "\n",
      " Data attributes, sizes, and coords \n",
      "\n",
      "\n",
      " Data sizes are: \n",
      " Frozen(OrderedDict([('day', 1), ('lat', 585), ('lon', 1386)]))\n",
      "\n",
      " Data coords are: \n",
      " Coordinates:\n",
      "  * day      (day) datetime64[ns] 2018-12-31\n",
      "  * lat      (lat) float64 49.4 49.36 49.32 49.28 ... 25.19 25.15 25.11 25.07\n",
      "  * lon      (lon) float64 -124.8 -124.7 -124.7 -124.6 ... -67.14 -67.1 -67.06\n",
      "<class 'xarray.core.utils.Frozen'>\n",
      "1\n",
      "1 1386 585\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from requests.exceptions import HTTPError\n",
    "import json\n",
    "# delete existing file if it exists\n",
    "gmfile = Path('../Data_v1_1/test_gm4.nc')\n",
    "exists = gmfile.exists()\n",
    "if exists:\n",
    "    os.remove(gmfile)\n",
    "    print('removed existing file')\n",
    "\n",
    "url2 = 'http://thredds.northwestknowledge.net:8080/thredds/ncss/agg_met_tmmx_1979_CurrentYear_CONUS.nc'\n",
    "payload2={'var': 'daily_maximum_temperature',\n",
    "        'disableLLSubset': 'on',\n",
    "        'disableProjSubset': 'on',\n",
    "        'horizStride': '1',\n",
    "        'time_start': '2018-12-31T00:00:00Z',\n",
    "        'time_end': '2018-12-31T00:00:00Z',\n",
    "        'timeStride': '1',\n",
    "        'accept': 'netcdf'}\n",
    "\n",
    "try:\n",
    "    myfile = requests.get(url2, params=payload2)\n",
    "    myfile.raise_for_status()\n",
    "except HTTPError as http_err:\n",
    "    print(f'HTTP error occurred: {http_err}')  # Python 3.6\n",
    "except Exception as err:\n",
    "    print(f'Other error occurred: {err}')  # Python 3.6\n",
    "else:\n",
    "    print('Success!')\n",
    "    print(myfile.url)\n",
    "        \n",
    "with open(gmfile, 'wb') as fh:\n",
    "    fh.write(myfile.content)\n",
    "    fh.close()\n",
    "\n",
    "ds = xr.open_dataset(gmfile)\n",
    "# print(ds)\n",
    "\n",
    "print('\\n The meta data is: \\n', json.dumps(ds.attrs, indent=4))\n",
    "lathandle=ds['lat']\n",
    "lonhandle=ds['lon']\n",
    "timehandle=ds['day']\n",
    "\n",
    "datahandle=ds['daily_maximum_temperature'] # for aggragated download\n",
    "\n",
    "#collect data to describe geotransform\n",
    "lonmin = float(ds.attrs['geospatial_lon_min'])\n",
    "latmax = float(ds.attrs['geospatial_lat_max'])\n",
    "lonres = float(ds.attrs['geospatial_lon_resolution'])\n",
    "latres = float(ds.attrs['geospatial_lon_resolution'])\n",
    "\n",
    "#Print some information on the data\n",
    "\n",
    "print('\\n Data attributes, sizes, and coords \\n') \n",
    "print('\\n Data sizes are: \\n', datahandle.sizes)\n",
    "print('\\n Data coords are: \\n', datahandle.coords)\n",
    "\n",
    "ts = datahandle.sizes\n",
    "print(type(ts))\n",
    "print(ts['day'])\n",
    "dayshape = ts['day']\n",
    "Lonshape = ts['lon']\n",
    "Latshape = ts['lat']\n",
    "print(dayshape, Lonshape, Latshape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "        nhru_v11  tmax\n",
      "0          76127   0.0\n",
      "1          76147   0.0\n",
      "2          76170   0.0\n",
      "3          76170   0.0\n",
      "4          76170   0.0\n",
      "...          ...   ...\n",
      "139802     57964   0.0\n",
      "139803     64080   0.0\n",
      "139804     64150   0.0\n",
      "139805     65633   0.0\n",
      "139806     18843   0.0\n",
      "\n",
      "[139807 rows x 2 columns]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([76127, 76147, 76170, ..., 64150, 65633, 18843], dtype=int64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfmap = pd.DataFrame(gdf.filter(['nhru_v11']))\n",
    "dfmap['tmax'] = 0.0\n",
    "print(type(dfmap))\n",
    "print(dfmap)\n",
    "nhm_id = dfmap.nhru_v11.values\n",
    "nhm_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "wght_UofI = pd.read_csv('../Data_v1_1/tmp_Gridmet_weights_hru_v1_1e.csv')\n",
    "wghts_id = wght_UofI.columns[1]\n",
    "wghts = wght_UofI.groupby(wghts_id)\n",
    "ndata = datahandle.values[dayshape-1,:,:].flatten(order='K')\n",
    "# mdata = np.ma.masked_array(ndata[wghts['grid_ids'].values.astype(int)],\n",
    "#                                    np.isnan(ndata[wghts['grid_ids'].values.astype(int)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val = dfmap.tmax.values\n",
    "index = dfmap[wghts_id].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit -r 1\n",
    "map_gridmet(dfmap, wghts_id, wghts, ndata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfmap.tmax.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_gridmet2(val, index, wght_id, wghts, data):\n",
    "    for i in range(val.shape[0]):\n",
    "        try:\n",
    "            weight_id_rows = wghts.get_group(index[i])\n",
    "            val[i] = np.nan_to_num(np_get_wval(data, weight_id_rows, index[i]) - 273.5)\n",
    "        except:\n",
    "            val[i] = netCDF4.default_fillvals['f8']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit -r 1\n",
    "map_gridmet2(val, index, wghts_id, wghts, ndata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(val.min())\n",
    "print(val.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numba\n",
    "fast_func = numba.jit(map_gridmet2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%timeit -r 1\n",
    "# fast_func(val, index, wghts_id, wghts, ndata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_gridmet3(val, index, wght_id, wghts, data):\n",
    "     \n",
    "    for i in range(val.shape[0]):\n",
    "        try:\n",
    "            weight_id_rows = wghts.get_group(index[i])\n",
    "            mdata = np.ma.masked_array(data[weight_id_rows['grid_ids'].values.astype(int)],\n",
    "                                   np.isnan(data[weight_id_rows['grid_ids'].values.astype(int)]))\n",
    "            tmp = np.ma.average(mdata, weights=wight_id_rows['w'])\n",
    "            if tmp is masked:\n",
    "                df.tmax.at[index] = netCDF4.default_fillvals['f8']\n",
    "            else:\n",
    "                df.tmax.at[index] = tmp-273.5\n",
    "#             df.tmax.at[index] = np.nan_to_num(np_get_wval2(data, weight_id_rows, row[wghts_id]) - 273.5)\n",
    "        except:\n",
    "            df.tmax.at[index] = netCDF4.default_fillvals['f8']\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numba\n",
    "fast_func = numba.jit(map_gridmet3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit -r 1\n",
    "fast_func(val, index, wghts_id, wghts, ndata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import Client\n",
    "client = Client(n_workers = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfmap['tmax'] = 0.0\n",
    "df = dd.from_pandas(dfmap, npartitions=3)\n",
    "print(type(df))\n",
    "# for index, i in df.iterrows():\n",
    "#     if index % 10000 == 0:\n",
    "#         print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df._meta)\n",
    "print(df._meta.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit -r 1\n",
    "res = df.map_partitions(map_gridmet_dask, wghts_id, unique_hru_ids, ndata,\n",
    "                        meta=(pd.DataFrame({'nhru_v11':np.dtype(np.int64), 'tmax':np.dtype(np.float64)}, index=[]))).compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfmap.tmax.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
